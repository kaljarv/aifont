{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp fontsampler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aifont.fontsampler\n",
    "\n",
    "> Utilities to create images from Google Fonts. Code mostly by https://erraticgenerator.com/blog/use-google-fonts-for-machine-learning-part1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering Font Images\n",
    "\n",
    "> Selecting Google Fonts and rendering font images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import re\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FontSampler:\n",
    "    \"\"\"Sample Google Fonts and render as images. `df` or `df_path` should point to font annotations\n",
    "       (see `create_font_annotations`), `font_path` to the root folder of the ofl fonts. Control\n",
    "       font selection with `variants`, `subsets` and `category`, which can be either strings or \n",
    "       regexs.\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame = None, df_path: str = \"data/google-fonts-annotation.csv\", \n",
    "        font_path: str = \"data/fonts\", variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None, image_width: int = 256, image_height: int = 256):\n",
    "        self.df = pd.read_csv(df_path) if df is None else df\n",
    "        self.font_path = font_path\n",
    "        self.variants = variants\n",
    "        self.subsets = subsets\n",
    "        self.category = category\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.font_index = -1\n",
    "        self.paths = self.filter_fonts_get_paths()\n",
    "\n",
    "    @property\n",
    "    def num_fonts(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def filter_fonts_get_paths(self, variants: list[str] = None, subsets: list[str] = None, \n",
    "        category: str = None) -> list[str]:\n",
    "        \"\"\"Filter the fonts list by the criteria and return a list of file paths.\"\"\"\n",
    "\n",
    "        df = self.df\n",
    "        font_path = self.font_path\n",
    "        if variants is None:\n",
    "            variants = self.variants\n",
    "        if subsets is None:\n",
    "            subsets = self.subsets\n",
    "        if category is None:\n",
    "            category = self.category\n",
    "\n",
    "        # exceptions\n",
    "        if variants is None or variants == [''] or variants == '': \n",
    "            variants = ['_']\n",
    "        if subsets is None or subsets == [''] or subsets == '': \n",
    "            subsets = ['_']\n",
    "        if category is None:\n",
    "            category = ''\n",
    "\n",
    "        # apply filters\n",
    "        regex_filters = variants + subsets + ['_' + category]\n",
    "        df_new = pd.concat([df.filter(regex=re.compile(regex, re.IGNORECASE), axis=1).sum(axis=1).astype(bool) for regex in regex_filters], axis=1)\n",
    "        mask = df_new.all(axis=1)\n",
    "        filtered_fontnames = list(df.loc[mask].family)\n",
    "        \n",
    "        # construct file paths\n",
    "        paths = []\n",
    "        for fontname in filtered_fontnames:\n",
    "            if variants == ['_']: # select all variants\n",
    "                sel = glob.glob(f'{font_path}/{fontname.lower()}/**/*.ttf', recursive=True)\n",
    "                paths.extend(sel)\n",
    "            else:\n",
    "                for variant in variants:\n",
    "                    sel = glob.glob(f'{font_path}/{fontname.lower()}/**/{fontname}-{variant}.ttf', recursive=True) \n",
    "                    for path in sel:\n",
    "                        paths.append(path)\n",
    "\n",
    "        if len(paths) == 0:\n",
    "            raise Exception(\"No matching fonts found!\")\n",
    "        # print(f'Found {len(paths)} font files.')\n",
    "\n",
    "        # Reset index\n",
    "        self.font_index = -1\n",
    "\n",
    "        random.shuffle(paths)\n",
    "        return paths\n",
    "\n",
    "    def render_text(self, text: str, text_size: int = None, x: int = None, y: int = None, \n",
    "        font_index: int = None, image_width: int = None, image_height: int = None, \n",
    "        as_normalised_array = False) -> Union[np.ndarray, Image.Image, None]:\n",
    "        \"\"\"Render the given text as black on white and return either as a normalised \n",
    "           numpy array of (alpha) values or a PIL Image. If called without font_index, \n",
    "           will iterate over all paths and return None once the end is reached.\"\"\"\n",
    "\n",
    "        paths = self.paths\n",
    "        if font_index is None:\n",
    "            if self.font_index >= len(paths):\n",
    "                self.font_index = -1\n",
    "                return None\n",
    "            self.font_index += 1\n",
    "            font_index = self.font_index\n",
    "\n",
    "        # sample text and font\n",
    "        if text_size is None:\n",
    "            text_size = round(self.image_height * .8)\n",
    "        if image_width is None:\n",
    "            image_width = self.image_width\n",
    "        if image_height is None:\n",
    "            image_height = self.image_height\n",
    "        \n",
    "        if x is None:\n",
    "            x = image_width  * .5\n",
    "        if y is None:\n",
    "            # Try to find a nice y location for the text keeping in mind that descenders\n",
    "            # will reach below this point and might thus fall offcanvas\n",
    "            y = text_size + max(0, (image_height - text_size * 1.5) / 2)\n",
    "        font = ImageFont.truetype(paths[font_index % len(paths)], text_size)\n",
    "\n",
    "        # get text info (not being used but may be useful)\n",
    "        # text_width, text_height = font.getsize(text)\n",
    "        # left, top, right, bottom = font.getbbox(text)\n",
    "        # print(left, top, right, bottom)\n",
    "\n",
    "        # create a blank canvas\n",
    "        canvas = Image.new('L', (image_width, image_height), 'white')\n",
    "\n",
    "        # draw the text onto the text canvas\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "        draw.text((x, y), text, 'black', font, anchor='ms')\n",
    "\n",
    "        # Convert to normalised list if needed\n",
    "        if as_normalised_array:\n",
    "            return np.reshape([(255 - x) / 255. for x in list(canvas.getdata())],\n",
    "                              (image_height, image_width))\n",
    "        return canvas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render a letter as a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x11F84C2B0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = FontSampler(category=\"sans-serif\")\n",
    "img = fs.render_text('A'); img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or as a numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (256, 256)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np_img = fs.render_text('A', as_normalised_array=True, font_index=0)\n",
    "print(f\"Shape: {np_img.shape}\")\n",
    "print(np_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it with `diffvg`, use the values as the A-band of the RGBA tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 256]), torch.Size([256, 256, 1]), torch.Size([256, 256, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "wd_ht = torch.tensor(np_img, dtype=torch.float32)\n",
    "wd_ht_a = torch.reshape(wd_ht, wd_ht.shape + tuple([1]))\n",
    "wd_ht_rgba = F.pad(input=wd_ht_a, pad=(3, 0, 0, 0, 0, 0), mode='constant', value=0)\n",
    "wd_ht.shape, wd_ht_a.shape, wd_ht_rgba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Font Metadata\n",
    "\n",
    "> Get font metadata from the Google Fonts API. Needed only once. You need an API key for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_font_annotations(data_path: str = \"data/webfonts.json\", api_key: str = None, \n",
    "    save_path = \"data/google-fonts-annotation.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Get Google Fonts metadata either from the API using `api_key` or from\n",
    "       a local file at `data_path` and save the data as csv in `save_path`.\n",
    "       Also returns the data frame.\"\"\"\n",
    "\n",
    "    assert api_key is not None or data_path is not None\n",
    "\n",
    "    if data_path is not None:\n",
    "        # Use JSON already downloaded\n",
    "        df = pd.read_json(data_path)\n",
    "    else:\n",
    "        # Download json data once\n",
    "        url = f\"https://www.googleapis.com/webfonts/v1/webfonts?key={api_key}\"\n",
    "        df = pd.read_json(url, orient='')\n",
    "\n",
    "    # flatten the JSON hierarchy (easier to handle this way)\n",
    "    df = pd.json_normalize(df['items'])\n",
    "\n",
    "    # select only the columns we need\n",
    "    cols = ['family', 'variants', 'subsets', 'category']\n",
    "    df = df[cols]\n",
    "    # df.head(5)\n",
    "\n",
    "    # Remove any space from family string so that it matchs with file name convention.\n",
    "    df.family = [name.replace(' ', '') for name in df.family]\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # one-hot encoding + prefix\n",
    "    df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('variants')),\n",
    "                            columns=[x for x in mlb.classes_],\n",
    "                            index=df.index))\n",
    "    df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('subsets')),\n",
    "                            columns=['subsets_' + x for x in mlb.classes_],\n",
    "                            index=df.index))\n",
    "    df = df.join(pd.get_dummies(df['category'], prefix=\"category\")).drop(['category'], axis=1)\n",
    "\n",
    "    col_names = {\n",
    "        \"100\": \"thin\",\n",
    "        \"100italic\": \"thinitalic\",\n",
    "        \"200\": \"extralight\",\n",
    "        \"200italic\": \"extralightitalic\",\n",
    "        \"300\": \"light\",\n",
    "        \"300italic\": \"lightitalic\",\n",
    "        \"400\": \"regular\",\n",
    "        \"regular\": \"regular\",\n",
    "        \"400italic\": \"italic\",\n",
    "        \"italic\": \"italic\",\n",
    "        \"500\": \"medium\",\n",
    "        \"500italic\": \"mediumitalic\",\n",
    "        \"600\": \"semibold\",\n",
    "        \"600italic\": \"semibolditalic\",\n",
    "        \"700\": \"bold\",\n",
    "        \"700italic\": \"bolditalic\",\n",
    "        \"800\": \"extrabold\",\n",
    "        \"800italic\": \"extrabolditalic\",\n",
    "        \"900\": \"black\",\n",
    "        \"900italic\": \"blackitalic\"\n",
    "    }\n",
    "    col_names = {k:f'variants_{v}' for k, v in col_names.items()}\n",
    "\n",
    "    df = df.rename(col_names, axis='columns')\n",
    "\n",
    "    # Export csv\n",
    "    if not save_path.endswith(\".csv\"):\n",
    "        save_path += \".csv\"\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_fontsampler.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
